{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3790c31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Random Forest model\n",
    "#10Fold\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Read CSV file\n",
    "df = pd.read_csv(\"CSV_PATH\")\n",
    "\n",
    "path_data = sklearn.utils.Bunch()\n",
    "#Read lavel information\n",
    "y = df[\"label\"]\n",
    "\n",
    "#Read factors\n",
    "#Change to your own factors to use\n",
    "X = df.loc[:, [ 'age', 'sex', 'T', 'DOI', 'RL', 'ly', 'v01', 'pn01', 'CLAM_score']]\n",
    " \n",
    "#feature list \n",
    "path_data[\"features\"] = [ 'age', 'sex', 'pT', 'DOI', 'side', 'ly', 'v','pn', 'WSI_score']\n",
    "\n",
    "# Random Forest Model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "# 10-Fold Cross Validationの\n",
    "cv = StratifiedKFold(n_splits=10, random_state=0, shuffle=True)\n",
    "\n",
    "# List for feature importance\n",
    "feature_importances_list = []\n",
    "\n",
    "# AUC、F1、Accuracy\n",
    "auc_scores = []\n",
    "f1_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "#Save model\n",
    "fold_models = [] \n",
    "\n",
    "# For grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(rf_model, param_grid, cv=cv, scoring='roc_auc')\n",
    "\n",
    "# each fold\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(X, y), start=1):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    rf_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "    y_pred_prob = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    auc = roc_auc_score(y_test, y_pred_prob)\n",
    "    auc_scores.append(auc)\n",
    "\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "    feature_importances_list.append(rf_model.feature_importances_)\n",
    "    fold_models.append(rf_model)\n",
    "\n",
    "\n",
    "    joblib.dump(rf_model, f'fold_{fold}_model.pkl')\n",
    "\n",
    "\n",
    "print(\"Mean AUC:\", np.mean(auc_scores))\n",
    "print(\"Mean F1 Score:\", np.mean(f1_scores))\n",
    "print(\"Mean Accuracy:\", np.mean(accuracy_scores))\n",
    "\n",
    "rf_model.fit(X, y)\n",
    "\n",
    "average_feature_importances = np.mean(feature_importances_list, axis=0)\n",
    "\n",
    "\n",
    "sorted_indices = np.argsort(average_feature_importances)[::-1]\n",
    "sorted_feature_importances = average_feature_importances[sorted_indices]\n",
    "sorted_feature_names = np.array(path_data[\"features\"])[sorted_indices]\n",
    "\n",
    "\n",
    "for idx, importance in enumerate(sorted_feature_importances):\n",
    "    print(f\"{sorted_feature_names[idx]}: {importance}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(X.shape[1]), sorted_feature_importances)\n",
    "\n",
    "# 特徴の名前をxticks()関数を使って設定\n",
    "plt.yticks(range(X.shape[1]), sorted_feature_names)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importance from Random Forest')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7659dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(X.shape[1]), sorted_feature_importances)\n",
    "\n",
    "plt.yticks(range(X.shape[1]), sorted_feature_names, fontsize=22)\n",
    "plt.xlabel('Feature Importance', fontsize=22)\n",
    "plt.ylabel('Features', fontsize=22)\n",
    "plt.title('Feature Importance from Random Forest', fontsize=22)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7d2d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('auc_accuracy_results.csv', 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(['Fold', 'AUC', 'Accuracy'])\n",
    "    for fold, (auc, accuracy) in enumerate(zip(auc_scores, accuracy_scores), start=1):\n",
    "        csvwriter.writerow([fold, auc, accuracy])\n",
    "        \n",
    "#学習したモデルの保存\n",
    "import joblib\n",
    "\n",
    "# 学習済みモデルのFold毎に保存\n",
    "joblib.dump(rf_model, 'final_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed7c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "# 新しいデータセットを読み込む1\n",
    "new_df = pd.read_csv(\"TEST_DATA_CSV_PATH\")\n",
    "\n",
    "# Features \n",
    "X_new = new_df.loc[:, [  'age', 'sex', 'T', 'DOI', 'RL', 'ly', 'v01', 'pn01', 'CLAM_score']]\n",
    "\n",
    "# Label\n",
    "y_true = new_df['label']\n",
    "\n",
    "auc_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "results = []\n",
    "\n",
    "# For each Fold\n",
    "for fold in range(1, 11):  \n",
    "    loaded_model = joblib.load(f'fold_{fold}_model.pkl')\n",
    "    y_pred_prob = loaded_model.predict_proba(X_new)[:, 1]\n",
    "    \n",
    "    # AUC\n",
    "    auc = roc_auc_score(y_true, y_pred_prob)\n",
    "    auc_scores.append(auc)\n",
    "\n",
    "    # label prediction\n",
    "    y_pred = (y_pred_prob >= 0.5).astype(int)\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    \n",
    "    fold_result = {\n",
    "        'Fold': fold,\n",
    "        'AUC': auc,\n",
    "        'Accuracy': accuracy\n",
    "    }\n",
    "    results.append(fold_result)\n",
    "    \n",
    "\n",
    "# Fold AUC and Accuracy\n",
    "for fold in range(10):\n",
    "    print(f\"Fold {fold + 1} - AUC: {auc_scores[fold]}, Accuracy: {accuracy_scores[fold]}\")\n",
    "\n",
    "# mean\n",
    "print(\"Mean AUC:\", sum(auc_scores) / len(auc_scores))\n",
    "print(\"Mean Accuracy:\", sum(accuracy_scores) / len(accuracy_scores))\n",
    "\n",
    "# To dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# CSV(Result)\n",
    "results_df.to_csv('Test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c1a6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
